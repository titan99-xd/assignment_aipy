{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "OQe6DjeYn56e",
        "outputId": "8693f4df-c510-4e7c-8b48-0e458e347a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Kernel=Linear): [[152   2]\n",
            " [  0 121]]\n",
            "Classification Report (Kernel=Linear):               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       154\n",
            "           1       0.98      1.00      0.99       121\n",
            "\n",
            "    accuracy                           0.99       275\n",
            "   macro avg       0.99      0.99      0.99       275\n",
            "weighted avg       0.99      0.99      0.99       275\n",
            "\n",
            "Confusion Matrix (Kernel=RBF): [[154   0]\n",
            " [  0 121]]\n",
            "Classification Report (Kernel=RBF):               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       154\n",
            "           1       1.00      1.00      1.00       121\n",
            "\n",
            "    accuracy                           1.00       275\n",
            "   macro avg       1.00      1.00      1.00       275\n",
            "weighted avg       1.00      1.00      1.00       275\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nBased on the results, both models performed excceptionally well. However, there are tiny differences:\\n- Linear karnel produced 2 false positives resulting in 99% accuracy. Precision, recall, and f1-score are very high but not perfect.\\n- RBF didn't misclassified any data; meaning there's no false results. Hence, the accuracy is 100%. recision, recall, and f1-score all are perfect.\\n\\nLinear kernel assumes that the data is linearly separable. It performed very well, but a small number of data were incorrectly classified (2 FP).\\n\\nRBF kernel is more flexible and can model complex, nonlinear decision boundries. In the above case, it perfectly classified all the data (no false results); meaning, it outperformed the linear model.\\n\\nSince RBF model generated 100% accuracy, it suggests that a nonlinear decision boundry is optimal for this dataset.\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/data_banknote_authentication.csv')\n",
        "\n",
        "# Selecting feature and target variables as X and y\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "# split dataset into 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "\n",
        "# Train SVM Model Linear\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# compute confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(f'Confusion Matrix (Kernel=Linear): {conf_matrix}')\n",
        "\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(f'Classification Report (Kernel=Linear): {class_report}')\n",
        "\n",
        "\n",
        "# Train SVM model RBF\n",
        "svm_model_rbf = SVC(kernel='rbf')\n",
        "svm_model_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_model_rbf.predict(X_test)\n",
        "\n",
        "# compute confusion matrix and classification report for rbf kernel\n",
        "conf_matrix_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "print(f'Confusion Matrix (Kernel=RBF): {conf_matrix_rbf}')\n",
        "\n",
        "class_report_rbf = classification_report(y_test, y_pred_rbf)\n",
        "print(f'Classification Report (Kernel=RBF): {class_report_rbf}')\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "Based on the results, both models performed excceptionally well. However, there are tiny differences:\n",
        "- Linear karnel produced 2 false positives resulting in 99% accuracy. Precision, recall, and f1-score are very high but not perfect.\n",
        "- RBF didn't misclassified any data; meaning there's no false results. Hence, the accuracy is 100%. recision, recall, and f1-score all are perfect.\n",
        "\n",
        "Linear kernel assumes that the data is linearly separable. It performed very well, but a small number of data were incorrectly classified (2 FP).\n",
        "\n",
        "RBF kernel is more flexible and can model complex, nonlinear decision boundries. In the above case, it perfectly classified all the data (no false results); meaning, it outperformed the linear model.\n",
        "\n",
        "Since RBF model generated 100% accuracy, it suggests that a nonlinear decision boundry is optimal for this dataset.\n",
        "\n",
        "\n",
        "'''"
      ]
    }
  ]
}